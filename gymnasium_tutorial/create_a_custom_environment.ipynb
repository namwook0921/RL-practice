{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOe5Br2Le20VbBUUq6+kA3G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"id":"mYsc6TpugEP9","executionInfo":{"status":"ok","timestamp":1744637693452,"user_tz":-540,"elapsed":51,"user":{"displayName":"NW Lee","userId":"08636088353176978033"}}},"outputs":[],"source":["from typing import Optional\n","import numpy as np\n","import gymnasium as gym\n","\n","\n","class GridWorldEnv(gym.Env):\n","\n","    def __init__(self, size: int = 5):\n","        # The size of the square grid\n","        self.size = size\n","\n","        # Define the agent and target location; randomly chosen in `reset` and updated in `step`\n","        self._agent_location = np.array([-1, -1], dtype=np.int32)\n","        self._target_location = np.array([-1, -1], dtype=np.int32)\n","\n","        # Observations are dictionaries with the agent's and the target's location.\n","        # Each location is encoded as an element of {0, ..., `size`-1}^2\n","        self.observation_space = gym.spaces.Dict(\n","            {\n","                \"agent\": gym.spaces.Box(0, size - 1, shape=(2,), dtype=int),\n","                \"target\": gym.spaces.Box(0, size - 1, shape=(2,), dtype=int),\n","            }\n","        )\n","\n","        # We have 4 actions, corresponding to \"right\", \"up\", \"left\", \"down\"\n","        self.action_space = gym.spaces.Discrete(4)\n","        # Dictionary maps the abstract actions to the directions on the grid\n","        self._action_to_direction = {\n","            0: np.array([1, 0]),  # right\n","            1: np.array([0, 1]),  # up\n","            2: np.array([-1, 0]),  # left\n","            3: np.array([0, -1]),  # down\n","        }\n","\n","\n","    def _get_obs(self):\n","          return {\"agent\": self._agent_location, \"target\": self._target_location}\n","\n","    def _get_info(self):\n","          return {\n","              \"distance\": np.linalg.norm(\n","                  self._agent_location - self._target_location, ord=1\n","              )\n","          }\n","    def reset(self, seed: Optional[int] = None, options: Optional[dict] = None):\n","        # We need the following line to seed self.np_random\n","        super().reset(seed=seed)\n","\n","        # Choose the agent's location uniformly at random\n","        self._agent_location = self.np_random.integers(0, self.size, size=2, dtype=int)\n","\n","        # We will sample the target's location randomly until it does not coincide with the agent's location\n","        self._target_location = self._agent_location\n","        while np.array_equal(self._target_location, self._agent_location):\n","            self._target_location = self.np_random.integers(\n","                0, self.size, size=2, dtype=int\n","            )\n","\n","        observation = self._get_obs()\n","        info = self._get_info()\n","\n","        return observation, info\n","\n","\n","    def step(self, action):\n","        # Map the action (element of {0,1,2,3}) to the direction we walk in\n","        direction = self._action_to_direction[action]\n","        # We use `np.clip` to make sure we don't leave the grid bounds\n","        self._agent_location = np.clip(\n","            self._agent_location + direction, 0, self.size - 1\n","        )\n","\n","        # An environment is completed if and only if the agent has reached the target\n","        terminated = np.array_equal(self._agent_location, self._target_location)\n","        truncated = False\n","        reward = 1 if terminated else 0  # the agent is only reached at the end of the episode\n","        observation = self._get_obs()\n","        info = self._get_info()\n","\n","        return observation, reward, terminated, truncated, info"]},{"cell_type":"code","source":["gym.register(\n","    id=\"gymnasium_env/GridWorld-v0\",\n","    entry_point=GridWorldEnv,\n",")"],"metadata":{"id":"N1ezqlilgMcz","executionInfo":{"status":"ok","timestamp":1744637701507,"user_tz":-540,"elapsed":8,"user":{"displayName":"NW Lee","userId":"08636088353176978033"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["gym.pprint_registry()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UjS5nX4Cg9vD","executionInfo":{"status":"ok","timestamp":1744637829104,"user_tz":-540,"elapsed":38,"user":{"displayName":"NW Lee","userId":"08636088353176978033"}},"outputId":"c5c4ff81-303d-41cf-8a59-f03ba533f818"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["===== classic_control =====\n","Acrobot-v1             CartPole-v0            CartPole-v1\n","MountainCar-v0         MountainCarContinuous-v0 Pendulum-v1\n","===== phys2d =====\n","phys2d/CartPole-v0     phys2d/CartPole-v1     phys2d/Pendulum-v0\n","===== box2d =====\n","BipedalWalker-v3       BipedalWalkerHardcore-v3 CarRacing-v3\n","LunarLander-v3         LunarLanderContinuous-v3\n","===== toy_text =====\n","Blackjack-v1           CliffWalking-v0        FrozenLake-v1\n","FrozenLake8x8-v1       Taxi-v3\n","===== tabular =====\n","tabular/Blackjack-v0   tabular/CliffWalking-v0\n","===== mujoco =====\n","Ant-v2                 Ant-v3                 Ant-v4\n","Ant-v5                 HalfCheetah-v2         HalfCheetah-v3\n","HalfCheetah-v4         HalfCheetah-v5         Hopper-v2\n","Hopper-v3              Hopper-v4              Hopper-v5\n","Humanoid-v2            Humanoid-v3            Humanoid-v4\n","Humanoid-v5            HumanoidStandup-v2     HumanoidStandup-v4\n","HumanoidStandup-v5     InvertedDoublePendulum-v2 InvertedDoublePendulum-v4\n","InvertedDoublePendulum-v5 InvertedPendulum-v2    InvertedPendulum-v4\n","InvertedPendulum-v5    Pusher-v2              Pusher-v4\n","Pusher-v5              Reacher-v2             Reacher-v4\n","Reacher-v5             Swimmer-v2             Swimmer-v3\n","Swimmer-v4             Swimmer-v5             Walker2d-v2\n","Walker2d-v3            Walker2d-v4            Walker2d-v5\n","===== None =====\n","GymV21Environment-v0   GymV26Environment-v0\n","===== gymnasium_env =====\n","gymnasium_env/GridWorld-v0\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"Zp2hEGsahxco"}},{"cell_type":"code","source":[],"metadata":{"id":"h2gKcMo9g6KT"},"execution_count":null,"outputs":[]}]}